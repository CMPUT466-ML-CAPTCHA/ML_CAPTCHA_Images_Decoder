{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    }
  },
  "cells": [
    {
      "source": [
        "## CNN Model (Notebook version)\n",
        "> CNN Captcha Recognition Model "
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "Import the libraries"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMALnUMlrwqo"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import random\n",
        "from PIL import Image\n",
        "from torchvision import transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "Load the data, please modify the path by yourself"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "ovGKMs-RtRkj",
        "outputId": "117a93c3-30ef-4f64-c070-1e1ab59b41db"
      },
      "source": [
        "# Load the data from the Google Drive\n",
        "# data_dir = Path(\"/content/drive/MyDrive/Data\")\n",
        "\n",
        "# path of data set for local\n",
        "data_dir = Path(\"./dataset\")\n",
        "\n",
        "images = list(data_dir.glob(\"*.jpg\")) #the size of dataset\n",
        "print(\"Number of images found: \", len(images))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "Show some samples (Optional)"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample_images =images[:4] \n",
        "_,ax = plt.subplots(2,2, figsize=(5,3))\n",
        "for i in range(4):\n",
        "    img = cv2.imread(str(sample_images[i]))\n",
        "    print(\"Shape of image: \", img.shape)\n",
        "    ax[i//2, i%2].imshow(img)\n",
        "    ax[i//2, i%2].axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "source": [
        "Customize the data set class"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, images, transform=None, target_transform=None, height=50, width=200):\n",
        "        self.transform = transform\n",
        "        self.num = len(images)\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "        self.images = np.zeros((self.num, height, width), dtype=np.float32)\n",
        "        self.labels = [0] * self.num\n",
        "\n",
        "        for i in range(self.num):\n",
        "            img = cv2.imread(str(images[i]))\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_RGBA2GRAY)\n",
        "            img = cv2.resize(img, (width, height))\n",
        "            self.labels[i] = images[i].name.split(\"_\")[0]\n",
        "            self.images[i, :, :] = img\n",
        "\n",
        "        sample = self.images[0]\n",
        "        self.labels = np.array(self.labels)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image = self.images[index]\n",
        "        label = self.images[index]\n",
        "        if self.transform != None:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num"
      ]
    },
    {
      "source": [
        "Split the data set"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# test data\n",
        "test_data = images[8000:]  # 2000 for test\n",
        "\n",
        "# the part for training\n",
        "training = images[:8000]\n",
        "valid_data = training[6000:]  # 2000 for validation\n",
        "train_data = training[:6000]  # 6000 for train\n",
        "\n",
        "print(\"test set size:\", len(test_data))\n",
        "print(\"validation set size:\", len(valid_data))\n",
        "print(\"train set size:\", len(train_data))\n",
        "\n",
        "train_set = CustomDataset(train_data, transform=transforms.ToTensor)\n",
        "valid_set = CustomDataset(valid_data, transform=transforms.ToTensor)\n",
        "test_set = CustomDataset(test_data, transform=transforms.ToTensor)"
      ]
    },
    {
      "source": [
        "## CNN Model"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "Coming soon"
      ],
      "cell_type": "markdown",
      "metadata": {}
    }
  ]
}