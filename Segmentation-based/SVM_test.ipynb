{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SVM_test.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q69OXo3svh50"
      },
      "source": [
        "# `SVM` testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVhntTHTufsL",
        "outputId": "ab126927-1615-409b-9f03-85ab4965f7fd"
      },
      "source": [
        "\"\"\"\n",
        "Support vector machine model for\n",
        "# `Completely Automated Public Turing test to tell Computers and Humans Apart`\n",
        "## **1) Data Preprocessing**\n",
        "Import the libraries\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import string\n",
        "import random\n",
        "import pathlib\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "if torch.cuda.is_available():\n",
        "    print(torch.cuda.get_device_name(0))\n",
        "\n",
        "# Parameters:\n",
        "NUMBER = [\"{}\".format(x) for x in range(10)]\n",
        "ALPHABET = list(string.ascii_uppercase)\n",
        "TABLE = NUMBER + ALPHABET # The table for CAPTCHA\n",
        "LEN_OF_TABLE = len(TABLE) # in total 10+26 alphanumeric characters\n",
        "LEN_OF_CAPTCHA = 6 # each picture contains 6 characters\n",
        "\n",
        "\"\"\"Load the dataset, please modify the path `data_dir` **accordingly**\"\"\"\n",
        "\n",
        "# Load the dataset from my Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "data_dir = pathlib.Path(\"/gdrive/My Drive/Data/\")\n",
        "images = list(data_dir.glob(\"*.jpg\")) # dataset as a list\n",
        "print(\"Number of images found:\", len(images)) # size of the dataset\n",
        "\n",
        "\"\"\"### Customise the dataset class\"\"\"\n",
        "\n",
        "# Convert the CAPTCHA into the (6*36,) vector (6 characters, 10 numbers + 26 uppercase/capital characters)\n",
        "# 1 means the CAPTCHA image contains this character in TABLE, 0 means otherwise\n",
        "def captcha_to_vector(captcha_str):\n",
        "    captcha_str = captcha_str.upper()\n",
        "    vector = np.zeros(36*LEN_OF_CAPTCHA, dtype=np.float32)\n",
        "    for i, char in enumerate(captcha_str):\n",
        "        ascii = ord(char) # Convert char into ASCII code\n",
        "        if 48 <= ascii <= 57:   # for digits\n",
        "            index = ascii - 48\n",
        "        elif 65 <= ascii <= 90: # for Latin letters\n",
        "            index = ascii - ord('A') + 10\n",
        "        vector[i*LEN_OF_TABLE+index] = 1.0\n",
        "    return vector\n",
        "\n",
        "# Convert the vector to the CAPTCHA (the input vector is different from the vector above)\n",
        "# Example: input: [1,2,34,2,6,7]; output: \"23Y378\"\n",
        "def vector_to_captcha(vector):\n",
        "    captcha_str = \"\"\n",
        "    for i in vector:\n",
        "        captcha_str += TABLE[i]\n",
        "    return captcha_str\n",
        "\n",
        "# Custom dataset\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, images, transform=None, target_transform=None, height=50, width=200):\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        self.images = images\n",
        "        self.width  = width\n",
        "        self.height = height\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Get the image with path\n",
        "        image = cv2.imread(str(self.images[index]))\n",
        "        # Increase contrast: segmentation-based so the preprocessing is more complicated\n",
        "        image = cv2.convertScaleAbs(image, alpha=3, beta=40)\n",
        "        # Erode noise\n",
        "        kernel = np.ones((1, 1), np.uint8)\n",
        "        image = cv2.erode(image, kernel, iterations=1)\n",
        "        # Convert the image into grayscale\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_RGBA2GRAY)\n",
        "        # Resize the image to ensure the size\n",
        "        image = cv2.resize(image, (self.width, self.height))\n",
        "        # Binarization of images\n",
        "        _, image = cv2.threshold(image, 20, 255, cv2.THRESH_BINARY|cv2.THRESH_OTSU)\n",
        "        # Method from dsp.stackexchange.com/questions/52089/removing-noisy-lines-from-image-opencv-python\n",
        "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1,3))\n",
        "        image = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\n",
        "        # Shear transformation, from thepythoncode.com/article/image-transformations-using-opencv-in-python#Image_Shearing\n",
        "        M = np.float32([[1, -0.5, 0],\n",
        "                        [0,    1, 0],\n",
        "                        [0,    0, 1]])\n",
        "        rows, cols = image.shape #(50, 200)\n",
        "        image = cv2.warpPerspective(image,M,(int(cols),int(rows)), cv2.INTER_LINEAR, borderValue=(255, 255, 255))\n",
        "        # Horizontal stretch\n",
        "        M = np.float32([[1.2, 0, 0],\n",
        "                        [0,   1, 0],\n",
        "                        [0,   0, 1]])\n",
        "        rows, cols = image.shape #(50, 200)\n",
        "        image = cv2.warpPerspective(image,M,(int(cols),int(rows)), cv2.INTER_LINEAR, borderValue=(255, 255, 255))\n",
        "\n",
        "        label = captcha_to_vector(self.images[index].name.split(\"_\")[0])\n",
        "        img_seg_list = []\n",
        "        label_lst = []\n",
        "        # Segmentation \n",
        "        for j in range(LEN_OF_CAPTCHA):\n",
        "            left = (j+1)*25\n",
        "            right = (j+2)*25\n",
        "            im_seg = image[:, left:right]\n",
        "            # Apply the transform to the image\n",
        "            if self.transform is not None:\n",
        "                img_seg_list.append(self.transform(im_seg))\n",
        "            else:\n",
        "                img_seg_list.append(im_seg)\n",
        "            label_lst.append(label[j*36:(j+1)*36])\n",
        "        return img_seg_list, label_lst\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "\"\"\"### Split and create datasets\"\"\"\n",
        "\n",
        "random.shuffle(images)\n",
        "NUMBER_Images = len(images)\n",
        "# test data\n",
        "test_data = images[int(0.8*NUMBER_Images):]     # last 2k images (20%) in dataset are for testing\n",
        "\n",
        "# the part for training\n",
        "training = images[:int(0.8*NUMBER_Images)]      # first 8k (80%) images in dataset are for training\n",
        "train_data = training\n",
        "\n",
        "print(\"Training set size:\\t\", len(train_data))\n",
        "print(\"Test set size:\\t\\t\", len(test_data))\n",
        "\n",
        "train_set = CustomDataset(train_data, transform=transforms.ToTensor())\n",
        "test_set  = CustomDataset(test_data,  transform=transforms.ToTensor())\n",
        "\n",
        "train_dataloader = DataLoader(dataset=train_set, batch_size=1, shuffle=True)#BATCH_SIZE=1\n",
        "test_dataloader  = DataLoader(dataset=test_set,  batch_size=1, shuffle=True)\n",
        "\n",
        "\"\"\"## **2) `SVM` Model** ($\\in$ segmentation-based algorithms)\"\"\"\n",
        "\n",
        "def get_data(dataloader):\n",
        "    X = []\n",
        "    Y = []\n",
        "    n = len(dataloader)\n",
        "    print(\"\")\n",
        "    for z in range(n):\n",
        "        if (z+1)%100 == 0: print(\"{}\".format(z+1))\n",
        "        i, l = next(iter(dataloader))\n",
        "        for image, label in zip(i, l):\n",
        "            image = image.to(device)\n",
        "            label = label.to(device)\n",
        "            label = label.reshape(1, 36)\n",
        "            label = torch.argmax(label, dim=1)\n",
        "            label = vector_to_captcha(label)\n",
        "            image = image.reshape(image.shape[2], image.shape[3]).cpu()\n",
        "            X.append(image.flatten().tolist())\n",
        "            Y.append(label)\n",
        "    new_Y = []\n",
        "    for j in range(len(Y)):\n",
        "        new_Y.append(Y[j][0])\n",
        "    return X, Y\n",
        "\n",
        "# Groups the original and the predicted characters together to into CAPTCHAs\n",
        "def group(lst):\n",
        "    n = len(lst)\n",
        "    i = 0\n",
        "    new_list = []\n",
        "    while i < n:\n",
        "        captcha = lst[i:i+LEN_OF_CAPTCHA] # six per group\n",
        "        new_list.append(''.join(captcha))\n",
        "        i += LEN_OF_CAPTCHA\n",
        "    return new_list\n",
        "\n",
        "\"\"\"**Training the support vector machine**\"\"\"\n",
        "\n",
        "# SVC Code from kaggle.com/sanesanyo/digit-recognition-using-svm-with-98-accuracy\n",
        "# Splitting the data into test and training set for our first simple linear SVM testing\n",
        "# Creating our linear SVM object\n",
        "from sklearn.svm import SVC\n",
        "regularization = [i for i in range(1,10,1)]\n",
        "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
        "train_x, train_y = get_data(train_dataloader)\n",
        "test_x,  test_y  = get_data(test_dataloader)\n",
        "for c in regularization:\n",
        "    for k in kernels:\n",
        "        clf = SVC(C=c, kernel=k)\n",
        "        clf.fit(train_x, train_y)\n",
        "        \n",
        "        \"\"\"Use the **`SVM`** to recognise new `CAPTCHA`\"\"\"\n",
        "        # Code for prediction and accuracy modified from the same Kaggle source\n",
        "        # Saving the predictions on the test set \n",
        "        y_predict = clf.predict(test_x)\n",
        "        # Group the original and the predicted characters together to a CAPTCHA\n",
        "        test_y_ = group(test_y)\n",
        "        y_predict = group(y_predict)\n",
        "        # Measuring the accuracy of our predictions\n",
        "        from sklearn import metrics\n",
        "        accuracy = metrics.accuracy_score(test_y_, y_predict)\n",
        "        print(\"Accuracy for SVM with C={} and kernel={}: {:.2f}%\".format(c,k,accuracy*100)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n",
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "Number of images found: 10000\n",
            "Training set size:\t 8000\n",
            "Test set size:\t\t 2000\n",
            "\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "800\n",
            "900\n",
            "1000\n",
            "1100\n",
            "1200\n",
            "1300\n",
            "1400\n",
            "1500\n",
            "1600\n",
            "1700\n",
            "1800\n",
            "1900\n",
            "2000\n",
            "2100\n",
            "2200\n",
            "2300\n",
            "2400\n",
            "2500\n",
            "2600\n",
            "2700\n",
            "2800\n",
            "2900\n",
            "3000\n",
            "3100\n",
            "3200\n",
            "3300\n",
            "3400\n",
            "3500\n",
            "3600\n",
            "3700\n",
            "3800\n",
            "3900\n",
            "4000\n",
            "4100\n",
            "4200\n",
            "4300\n",
            "4400\n",
            "4500\n",
            "4600\n",
            "4700\n",
            "4800\n",
            "4900\n",
            "5000\n",
            "5100\n",
            "5200\n",
            "5300\n",
            "5400\n",
            "5500\n",
            "5600\n",
            "5700\n",
            "5800\n",
            "5900\n",
            "6000\n",
            "6100\n",
            "6200\n",
            "6300\n",
            "6400\n",
            "6500\n",
            "6600\n",
            "6700\n",
            "6800\n",
            "6900\n",
            "7000\n",
            "7100\n",
            "7200\n",
            "7300\n",
            "7400\n",
            "7500\n",
            "7600\n",
            "7700\n",
            "7800\n",
            "7900\n",
            "8000\n",
            "\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "800\n",
            "900\n",
            "1000\n",
            "1100\n",
            "1200\n",
            "1300\n",
            "1400\n",
            "1500\n",
            "1600\n",
            "1700\n",
            "1800\n",
            "1900\n",
            "2000\n",
            "Accuracy for SVM with C=1 and kernel=linear: 29.30%\n",
            "Accuracy for SVM with C=1 and kernel=poly: 73.25%\n",
            "Accuracy for SVM with C=1 and kernel=rbf: 78.60%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-souCPp_TAo"
      },
      "source": [
        "Accuracy for SVM with C=1 and kernel=linear: 30.05%\n",
        "\n",
        "Accuracy for SVM with C=1 and kernel=poly: 75.6%\n",
        "\n",
        "Accuracy for SVM with C=1 and kernel=rbf: 80.2%\n",
        "\n",
        "Accuracy for SVM with C=2 and kernel=linear: 27.6%\n",
        "\n",
        "Accuracy for SVM with C=2 and kernel=poly: 75.05%\n",
        "\n",
        "Accuracy for SVM with C=2 and kernel=rbf: 82.75%\n",
        "\n",
        "Accuracy for SVM with C=3 and kernel=linear: 26.25%\n",
        "\n",
        "Accuracy for SVM with C=3 and kernel=poly: 75.10%\n",
        "\n",
        "Accuracy for SVM with C=3 and kernel=rbf: 81.45%\n",
        "\n",
        "Accuracy for SVM with C=0.01 and kernel=linear: 44.55%\n",
        "\n",
        "Accuracy for SVM with C=0.01 and kernel=poly: 63.00%\n",
        "\n",
        "Accuracy for SVM with C=0.01 and kernel=rbf: 29.60%\n",
        "\n",
        "Accuracy for SVM with C=100 and kernel=linear: 24.75%\n",
        "\n",
        "Accuracy for SVM with C=100 and kernel=poly: 71.55%\n",
        "\n",
        "Accuracy for SVM with C=100 and kernel=rbf: 79.15%\n"
      ]
    }
  ]
}